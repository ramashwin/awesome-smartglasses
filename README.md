# smartglasses-research
A collection of research papers on smart glasses, more specifically Optical See-through Head-Mounted Displays (OST-HMDs). 

Currently, we curate papers on 3 areas:

# Table of contents
1. [Design guidelines](#design)
2. [Interaction Techniques](#interaction)
3. [Prototyping Tools](#prototype)

## Design Guidelines <a name="design"></a>

| Year | Venue | Paper                                                                                                                                                            |
|------|-------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 2022 | CHI   | [Does Dynamically Drawn Text Improve Learning? Investigating the Effect of Text Presentation Styles in Video Learning](https://doi.org/10.1145/3491102.3517499)  |
| 2022 | CHI   | [Paracentral and near-peripheral visualizations: Towards attention-maintaining secondary information presentation on OHMDs during in-person social interactions](https://doi.org/10.1145/3491102.3502127)  |
| 2021 | IMWUT | [LSVP: Towards Effective On-the-go Video Learning Using Optical Head-Mounted Displays](https://doi.org/10.1145/3448118)                                          |
| 2020 | NordiCHI   | [Effects of Position and Alignment of Notifications on AR Glasses during Social Interaction](https://doi.org/10.1145/3419249.3420095)                       |
| 2020 | MuC   		| [Effects of position of real-time translation on AR glasses](https://doi.org/10.1145/3404983.3405523)                       |
| 2019 | VR   		| [Text Presentation for Augmented Reality Applications in Dual-Task Situations](https://doi.org/10.1109/VR.2019.8797992)                             |
| 2019 | VR   		| [PeriText: Utilizing Peripheral Vision for Reading Text on Augmented Reality Smart Glasses](https://doi.org/10.1109/VR.2019.8798065)                             |
| 2019 | SUI   		| [Effects of Dark Mode on Visual Fatigue and Acuity in Optical See-Through Head-Mounted Displays](https://doi.org/10.1145/3357251.3357584)                             |
| 2019 | ISWC   	| [Readability and Legibility of Fonts Considering Shakiness of Head Mounted Displays](https://doi.org/10.1145/3341163.3347748)                             |
| 2018 | CHI   		| [Reading on Smart Glasses: The Effect of Text Position, Presentation Type and Walking](https://doi.org/10.1145/3173574.3173619)                             |
| 2016 | ChineseCHI | [Positioning Glass: Investigating Display Positions of Monocular Optical See-Through Head-Mounted Display](https://doi.org/10.1145/2948708.2948713)          |
| 2014 | ACE 		| [NotifEye: using interactive glasses to deal with notifications while walking in public](https://doi.org/10.1145/2663806.2663824)    |
| 2014 | TVCG 		| [Text readability in head-worn displays: color and style optimization in video versus optical see-through devices](https://doi.org/10.1109/TVCG.2013.86)    |
| 2014 | SIGMOBILE 	| [Managing mobile text in head mounted displays: studies on visual preference and text placement](https://doi.org/10.1145/2636242.2636246)    |
| 2008 | ISMAR 		| [An information layout method for an optical see-through head mounted display focusing on the viewability](https://doi.org/10.1109/ISMAR.2008.4637340)    |
| 2006 | Presence   | [The effects of text drawing styles, background textures, and natural lighting on text legibility in outdoor augmented reality](https://doi.org/10.1162/pres.2006.15.1.16)          |

## Interaction Techniques <a name="interaction"></a>

### Voice-based 

| Year | Venue | Paper                                                                                                                                                            |
|------|-------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 2021 | ICMI  | [Interaction Modalities for Notification Signals in Augmented Reality](https://doi.org/10.1145/3462244.3479898)                                              	  |
| 2020 | CHI   | [EYEditor: Towards On-the-Go Heads-up Text Editing UsingVoice and Manual Input](https://doi.org/10.1145/3313831.3376173)                                              	  |

### Gaze-based

### Gesture-based
| Year | Venue | Paper                                                                                                                                                            |
|------|-------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 2020 | CHI   | [Walk The Line: Leveraging Lateral Shifts of the Walking Path as an Input Modality for Head-Mounted Displays](https://doi.org/10.1145/3313831.3376852)  		  |
| 2021 | MobileHCI  | [Ubiquitous Interactions for Heads-Up Computing: Understanding Usersâ€™ Preferences for Subtle Interaction Techniques in Everyday Settings](https://doi.org/10.1145/3447526.3472035)                                          																																	      |
## Protoyping Tools <a name="prototype"></a>